{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "Overfitting\n",
    "- Overly sensitive to noise\n",
    "- Increased sensitivity to subtle effects\n",
    "- Poor generalization to new data\n",
    "- Overparametrized models become more difficult to estimate\n",
    "\n",
    "Underfitting\n",
    "- Less sensitive to noise\n",
    "- Less likely to detect true effects\n",
    "- Reduced generalization to new data\n",
    "- Parameters are better estimated\n",
    "- Good results with small sample sizes\n",
    "\n",
    "With 1-2 dimensions: Visualize the data and make informed decision\n",
    "\n",
    "With more dimensions: Use cross-validation\n",
    "\n",
    "## Avoid overfitting\n",
    "\n",
    "- Use cross-validation (training/held-out/test sets)\n",
    "- Use regularization (penalize complexity)\n",
    "\n",
    "## Cross-validation\n",
    "Split data into training and test sets\n",
    "- Training set: Fit model parameters\n",
    "- Test set: Evaluate model performance\n",
    "- Hold-out set (dev-set): Tune model parameters\n",
    "\n",
    "K-fold cross-validation\n",
    "- Split data into K folds\n",
    "- Train on K-1 folds\n",
    "- Test on the remaining fold\n",
    "- Repeat K times\n",
    "\n",
    "## Generalization\n",
    "\n",
    "Generalization: The model works well on unseen data.\n",
    "\n",
    "Generalization boundaries: The population you want to apply to the model.\n",
    "\n",
    "Simple example:\n",
    "$weight = \\beta_1 * height + \\beta_2 * calories$\n",
    "\n",
    "    Generalization boundaries: \n",
    "    - Must work on humans (both sexes, all countries)\n",
    "    - Doesn't need to work on children\n",
    "    - Doesn't need to work on animals\n",
    "\n",
    "Generalization entails the some loss of accuracy.\n",
    "\n",
    "## Manual cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris') # panda dataframe\n",
    "\n",
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values, dtype=torch.float32)\n",
    "\n",
    "# transform species to numeric values\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "labels[iris.species == 'versicolor'] = 1\n",
    "labels[iris.species == 'virginica'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data into training and test sets\n",
    "\n",
    "propTraining = 0.8 # proportion of data to use for training\n",
    "nTraining = int(propTraining * len(labels)) # number of training samples\n",
    "\n",
    "traintestBool = np.zeros(len(labels), dtype=bool) # boolean array\n",
    "\n",
    "# this is not random\n",
    "#traintestBool[range(nTraining)] = True\n",
    "\n",
    "items2use4training = np.random.choice(range(len(labels)), size=nTraining, replace=False)\n",
    "traintestBool[items2use4training] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of full data\n",
      "tensor(1.)\n",
      " \n",
      "Average of training data\n",
      "tensor(1.0750)\n",
      " \n",
      "Average of test data\n",
      "tensor(0.7000)\n"
     ]
    }
   ],
   "source": [
    "# test whether the split is correct\n",
    "print('Average of full data')\n",
    "print(torch.mean(labels.float()))\n",
    "print(' ')\n",
    "\n",
    "print('Average of training data')\n",
    "print(torch.mean(labels[traintestBool].float()))\n",
    "print(' ')\n",
    "\n",
    "print('Average of test data')\n",
    "print(torch.mean(labels[~traintestBool].float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "\n",
    "ANNiris = nn.Sequential(\n",
    "    nn.Linear(4, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 3)\n",
    ")\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(ANNiris.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4])\n",
      "torch.Size([120, 4])\n",
      "torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "# entire dataset\n",
    "print(data.shape)\n",
    "\n",
    "#training data\n",
    "print(data[traintestBool].shape)\n",
    "# test data\n",
    "print(data[~traintestBool].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "# initialize loss array\n",
    "losses = np.zeros(num_epochs)\n",
    "ongoinAccuracy = np.zeros(num_epochs)\n",
    "\n",
    "# loop over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    yHat = ANNiris(data[traintestBool]) # forward pass\n",
    "    ongoinAccuracy[epoch] = torch.mean((torch.argmax(yHat, dim=1) == labels[traintestBool]).float())\n",
    "\n",
    "    loss = loss_fn(yHat, labels[traintestBool]) # compute loss\n",
    "    losses[epoch] = loss.item() # store loss for this epoch\n",
    "\n",
    "    optimizer.zero_grad() # zero gradients\n",
    "    loss.backward() # backward pass\n",
    "    optimizer.step() # update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on test set\n",
    "predictions = ANNiris(data[traintestBool,:])\n",
    "trainacc = torch.mean((torch.argmax(predictions, dim=1) == labels[traintestBool]).float())\n",
    "\n",
    "# final forward pass\n",
    "predictions = ANNiris(data[~traintestBool,:])\n",
    "testacc = torch.mean((torch.argmax(predictions, dim=1) == labels[~traintestBool]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: tensor(0.9833)\n",
      "Test accuracy: tensor(0.9667)\n"
     ]
    }
   ],
   "source": [
    "# report accuracy\n",
    "\n",
    "print('Training accuracy: ' + str(trainacc))\n",
    "print('Test accuracy: ' + str(testacc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris') # panda dataframe\n",
    "\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values, dtype=torch.float32)\n",
    "\n",
    "# transform species to numeric values\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "labels[iris.species == 'versicolor'] = 1\n",
    "labels[iris.species == 'virginica'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  12  13  14]\n",
      " [ 21  22  23  24]\n",
      " [ 31  32  33  34]\n",
      " [ 41  42  43  44]\n",
      " [ 51  52  53  54]\n",
      " [ 61  62  63  64]\n",
      " [ 71  72  73  74]\n",
      " [ 81  82  83  84]\n",
      " [ 91  92  93  94]\n",
      " [101 102 103 104]]\n",
      "[False False False False False  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# create fake dataset\n",
    "\n",
    "fakedata = np.tile(np.array([1, 2, 3, 4]), (10, 1)) + np.tile(10*np.arange(1,11), (4, 1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata)\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:(8, 4)\n",
      "Test data size:(2, 4)\n",
      " \n",
      "Training data: \n",
      "[[31 32 33 34]\n",
      " [91 92 93 94]\n",
      " [61 62 63 64]\n",
      " [41 42 43 44]\n",
      " [21 22 23 24]\n",
      " [81 82 83 84]\n",
      " [11 12 13 14]\n",
      " [51 52 53 54]]\n",
      " \n",
      "Test data: \n",
      "[[ 71  72  73  74]\n",
      " [101 102 103 104]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# use scikit-learn to split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(fakedata, fakelabels, test_size=0.2)\n",
    "\n",
    "print('Training data size:' + str(train_data.shape))\n",
    "print('Test data size:' + str(test_data.shape))\n",
    "print(' ')\n",
    "\n",
    "print('Training data: ' )\n",
    "print(train_data)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ' )\n",
    "print(test_data)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createANewModel():\n",
    "    ANNiris = nn.Sequential(\n",
    "        nn.Linear(4, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 3)\n",
    "    )\n",
    "\n",
    "    # define the loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # define the optimizer\n",
    "    learning_rate = 1e-2\n",
    "    optimizer = torch.optim.SGD(ANNiris.parameters(), lr=learning_rate)\n",
    "    return ANNiris, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 32, 33, 34],\n",
       "       [91, 92, 93, 94],\n",
       "       [61, 62, 63, 64],\n",
       "       [41, 42, 43, 44],\n",
       "       [21, 22, 23, 24],\n",
       "       [81, 82, 83, 84],\n",
       "       [11, 12, 13, 14],\n",
       "       [51, 52, 53, 54]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "def trainTheModel(ANNiris, loss_fn, optimizer, train_data, train_labels, test_data, test_labels, num_epochs=100):\n",
    "    # training loop\n",
    "    # initialize loss array\n",
    "    losses = np.zeros(num_epochs)\n",
    "    ongoinAccuracy = np.zeros(num_epochs)\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        yHat = ANNiris(train_data) # forward pass\n",
    "        ongoinAccuracy[epoch] = torch.mean((torch.argmax(yHat, dim=1) == train_labels).float())\n",
    "\n",
    "        loss = loss_fn(yHat, train_labels) # compute loss\n",
    "        losses[epoch] = loss.item() # store loss for this epoch\n",
    "\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "        loss.backward() # backward pass\n",
    "        optimizer.step() # update parameters\n",
    "\n",
    "    # compute accuracy on test set\n",
    "    predictions = ANNiris(train_data)\n",
    "    trainacc = torch.mean((torch.argmax(predictions, dim=1) == train_labels).float())\n",
    "\n",
    "    # final forward pass\n",
    "    predictions = ANNiris(test_data)\n",
    "    testacc = torch.mean((torch.argmax(predictions, dim=1) == test_labels).float())\n",
    "\n",
    "    # report accuracy\n",
    "\n",
    "    print('Training accuracy: ' + str(trainacc))\n",
    "    print('Test accuracy: ' + str(testacc))\n",
    "\n",
    "    return losses, ongoinAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: tensor(0.7167)\n",
      "Test accuracy: tensor(0.5333)\n"
     ]
    }
   ],
   "source": [
    "ANNIris, lossfun, optimizer = createANewModel()\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2)\n",
    "losses, ongoinAccuracy = trainTheModel(ANNIris, lossfun, optimizer, \n",
    "                                       train_data, \n",
    "                                       train_labels, \n",
    "                                       test_data, \n",
    "                                       test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69166666, 0.68333334, 0.68333334, 0.68333334, 0.65833336,\n",
       "       0.64999998, 0.64999998, 0.65833336, 0.67500001, 0.68333334,\n",
       "       0.68333334, 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "       0.69999999, 0.70833331, 0.70833331, 0.70833331, 0.70833331,\n",
       "       0.70833331, 0.70833331, 0.70833331, 0.70833331, 0.70833331,\n",
       "       0.70833331, 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "       0.71666664, 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "       0.71666664, 0.71666664, 0.71666664, 0.71666664, 0.71666664])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ongoinAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
