{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Regularization is a technique used to reduce the complexity of the model and prevent overfitting.\n",
    "\n",
    "- Penalize \"memorization\" overlearning\n",
    "- Helps generalize to new data\n",
    "- Changes the representation of learning\n",
    "\n",
    "Other observations:\n",
    "- can increase or decrease training time\n",
    "- can decrease accuracy but increase generalization\n",
    "- works better for large models with multiple hidden layers\n",
    "- generally works better with more data\n",
    "\n",
    "Families of regularization:\n",
    "- L1/L2 regularization - add cost to the loss function\n",
    "- Modify the model - dropout, batch normalization, early stopping\n",
    "- Data augmentation - add noise to the data\n",
    "- Ensemble methods - bagging, boosting\n",
    "\n",
    "How to think about regularization:\n",
    "- Adds a cost to the complexity of the solution\n",
    "- Forces the solution to be smooth\n",
    "- Prevents the model from learning \"too much\" - item specific details\n",
    "\n",
    "## L1/L2 regularization (Dropout)\n",
    "Removes nodes randomly during learning. This forces the network to learn with different nodes and not rely on a single node.\n",
    "\n",
    "L1/L2 regularization adds a cost to the loss function. This cost is proportional to the sum of the weights. This forces the network to learn with smaller weights.\n",
    "\n",
    "Cost function: $ J = \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{(i)}, y^{(i)})$\n",
    "\n",
    "Regularized cost function: $ J = \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{(i)}, y^{(i)}) + \\frac{\\lambda}{2m} \\sum_{l=1}^{L} ||w^{[l]}||^2_F $\n",
    "\n",
    "Where $||w^{[l]}||^2_F$ is the Frobenius norm of the weights of layer $l$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
